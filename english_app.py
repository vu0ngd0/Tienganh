import streamlit as st
import pandas as pd
from gtts import gTTS
import io
import os
import copy
import json
import gspread
import base64
from oauth2client.service_account import ServiceAccountCredentials

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="English Pro (Final)", page_icon="‚òÅÔ∏è", layout="wide")

# --- CSS ---
st.markdown("""
<style>
    div.stButton > button { height: 60px; font-size: 20px; font-weight: bold; border-radius: 12px; }
    /* CSS cho n√∫t Link (st.link_button) ƒë·ªÉ n√≥ to b·∫±ng c√°c n√∫t kh√°c */
    a[data-testid="stLinkButton"] { 
        height: 60px; 
        font-size: 20px; 
        font-weight: bold; 
        border-radius: 12px; 
        display: flex;
        align-items: center;
        justify-content: center;
    }
    .stToast { position: fixed; top: 50px; right: 10px; width: 300px; }
</style>
""", unsafe_allow_html=True)

# --- KHU V·ª∞C C√ÅC H√ÄM H·ªñ TR·ª¢ ---

def autoplay_audio(audio_fp):
    """H√†m ph√°t √¢m thanh HTML5 m·∫°nh m·∫Ω cho Mobile/iPhone"""
    try:
        b64 = base64.b64encode(audio_fp.getvalue()).decode()
        md = f"""
            <audio controls autoplay style="width: 100%; margin-top: 10px;">
            <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
            </audio>
            """
        st.markdown(md, unsafe_allow_html=True)
    except Exception as e:
        st.error(f"L·ªói ph√°t √¢m thanh: {e}")

@st.cache_resource
def connect_gsheet():
    try:
        if "connections" in st.secrets and "gsheets" in st.secrets["connections"]:
            creds_dict = dict(st.secrets["connections"]["gsheets"])
        else:
            creds_dict = dict(st.secrets["gcp_service_account"])

        if "private_key" in creds_dict:
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")

        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        return client
    except Exception as e:
        return None

def get_sheet_url():
    url = ""
    if "connections" in st.secrets and "gsheets" in st.secrets["connections"]:
        secrets_gsheets = st.secrets["connections"]["gsheets"]
        if "spreadsheet" in secrets_gsheets:
            url = secrets_gsheets["spreadsheet"]
        elif "sheet_url" in secrets_gsheets:
            url = secrets_gsheets["sheet_url"]
    
    if not url and "sheet_url" in st.secrets:
        url = st.secrets["sheet_url"]
    return url

def save_to_gsheet(queue, mastered):
    sheet_url = get_sheet_url()
    if not sheet_url:
        st.error("Ch∆∞a t√¨m th·∫•y Link Google Sheet trong secrets.toml")
        return

    client = connect_gsheet()
    if not client: return
    
    try:
        sh = client.open_by_url(sheet_url)
        
        try: ws_queue = sh.worksheet("Queue")
        except: ws_queue = sh.add_worksheet(title="Queue", rows=1000, cols=10)
        
        ws_queue.clear()
        if queue:
            headers = list(queue[0].keys())
            data = [headers] + [[str(d.get(k, '')) for k in headers] for d in queue]
            ws_queue.update(range_name='A1', values=data)
        else:
            ws_queue.update(range_name='A1', values=[["Empty"]])

        try: ws_mastered = sh.worksheet("Mastered")
        except: ws_mastered = sh.add_worksheet(title="Mastered", rows=1000, cols=10)
        
        ws_mastered.clear()
        if mastered:
            headers = list(mastered[0].keys())
            data = [headers] + [[str(d.get(k, '')) for k in headers] for d in mastered]
            ws_mastered.update(range_name='A1', values=data)
        else:
            ws_mastered.update(range_name='A1', values=[["Empty"]])
            
    except Exception as e:
        st.error(f"L·ªói l∆∞u data: {e}")

def load_from_gsheet():
    sheet_url = get_sheet_url()
    if not sheet_url: return None, None
    
    client = connect_gsheet()
    if not client: return None, None
    
    try:
        sh = client.open_by_url(sheet_url)
        
        def clean_records(records):
            cleaned = []
            for r in records:
                if len(r) == 1 and list(r.values())[0] == "Empty": continue
                if 'progress' in r:
                    try: r['progress'] = int(r['progress'])
                    except: r['progress'] = 0
                cleaned.append(r)
            return cleaned

        try:
            ws_queue = sh.worksheet("Queue")
            q_data = clean_records(ws_queue.get_all_records())
        except: q_data = []
        
        try:
            ws_mastered = sh.worksheet("Mastered")
            m_data = clean_records(ws_mastered.get_all_records())
        except: m_data = []
            
        return q_data, m_data

    except Exception as e:
        return None, None

@st.cache_data
def load_vocabulary(uploaded_file=None):
    df = None
    encodings = ['utf-8', 'utf-8-sig', 'cp1258', 'latin1', 'cp1252']
    file_source = uploaded_file if uploaded_file else ('vocabulary.csv' if os.path.exists('vocabulary.csv') else None)
    
    if file_source:
        for enc in encodings:
            try:
                if hasattr(file_source, 'seek'): file_source.seek(0)
                df = pd.read_csv(file_source, encoding=enc)
                if 'Word' in df.columns or 'English' in df.columns: break
            except: continue

    if df is None: return None

    df.columns = [c.strip() for c in df.columns]
    rename = {'English': 'Word', 'Ti·∫øng Anh': 'Word', 'Vietnamese': 'Vi·ªát Note', 'Ti·∫øng Vi·ªát': 'Vi·ªát Note', 'C·∫•p ƒë·ªô': 'Level'}
    df = df.rename(columns=rename)
    
    df = df.dropna(subset=['Word', 'Vi·ªát Note'])
    if 'Level' not in df.columns: df['Level'] = 'Other'
    
    vocab_data = {}
    for level, group in df.groupby('Level'):
        level = str(level).strip()
        words = []
        for _, row in group.iterrows():
            words.append({
                "english": str(row['Word']).strip(),
                "vietnamese": str(row['Vi·ªát Note']).strip(),
                "pronunciation": str(row.get('Phonetics', '')).strip(),
                "example": str(row.get('Example', '')).strip(),
                "type": str(row.get('Type', '')).strip(),
                "progress": 0
            })
        vocab_data[level] = {"name": f"Level {level}", "words": words}
    return vocab_data

def text_to_speech(text):
    try:
        tts = gTTS(text=text, lang='en')
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        return fp
    except: return None

def handle_review(word, status):
    current = st.session_state.learning_queue.pop(0)
    
    if status == "forget":
        current['progress'] = 0
        st.session_state.learning_queue.insert(min(len(st.session_state.learning_queue), 10), current)
        st.toast(f"H·ªçc l·∫°i: {current['english']}", icon="üîÑ")
    elif status == "remember":
        current['progress'] += 1
        if current['progress'] >= 3:
            st.session_state.mastered_words.append(current)
            st.balloons()
        else:
            offset = 30 if current['progress'] == 1 else 50
            st.session_state.learning_queue.insert(min(len(st.session_state.learning_queue), offset), current)
            st.toast(f"ƒê√£ nh·ªõ: {current['english']}", icon="‚úÖ")
            
    st.session_state.show_meaning = False
    # Kh√¥ng c·∫ßn reset image state n·ªØa v√¨ ch√∫ng ta d√πng link
    
    save_to_gsheet(st.session_state.learning_queue, st.session_state.mastered_words)

# --- GIAO DI·ªÜN V√Ä LOGIC CH√çNH ---

DEFAULT_DATA = {"Demo": {"name": "Demo", "words": [{"english": "Hello", "vietnamese": "Xin ch√†o", "progress": 0}]}}

with st.sidebar:
    st.title("‚öôÔ∏è C√†i ƒë·∫∑t")
    uploaded_file = st.file_uploader("Upload CSV T·ª´ v·ª±ng (n·∫øu c·∫ßn ƒë·ªïi)", type=['csv'])
    
    st.divider()
    if get_sheet_url():
        st.success("‚úÖ ƒê√£ k·∫øt n·ªëi Google Sheet")
    else:
        st.error("‚ö†Ô∏è Ch∆∞a t√¨m th·∫•y c·∫•u h√¨nh Google Sheet")

# 1. Load t·ª´ v·ª±ng
VOCABULARY_DATA = load_vocabulary(uploaded_file)
if not VOCABULARY_DATA: VOCABULARY_DATA = DEFAULT_DATA

# 2. Kh·ªüi t·∫°o Session
if 'initialized' not in st.session_state:
    st.session_state.initialized = True
    st.session_state.show_meaning = False
    
    with st.spinner("ƒêang ƒë·ªìng b·ªô d·ªØ li·ªáu t·ª´ Cloud..."):
        cloud_queue, cloud_mastered = load_from_gsheet()
    
    if cloud_queue is not None:
        st.session_state.learning_queue = cloud_queue
        st.session_state.mastered_words = cloud_mastered
        
        found_topic = list(VOCABULARY_DATA.keys())[0]
        if cloud_queue:
            first_word = cloud_queue[0]['english']
            for topic, data in VOCABULARY_DATA.items():
                for w in data['words']:
                    if w['english'] == first_word:
                        found_topic = topic
                        break
        st.session_state.selected_topic = found_topic
        st.toast("üìÇ ƒê√£ t·ª± ƒë·ªông n·∫°p ti·∫øn ƒë·ªô c≈©!", icon="‚úÖ")
        
    else:
        first_topic = list(VOCABULARY_DATA.keys())[0]
        st.session_state.selected_topic = first_topic
        st.session_state.learning_queue = copy.deepcopy(VOCABULARY_DATA[first_topic]['words'])
        st.session_state.mastered_words = []

if 'previous_topic' not in st.session_state:
    st.session_state.previous_topic = st.session_state.selected_topic

# --- GIAO DI·ªÜN CH√çNH ---
st.title("‚òÅÔ∏è English Pro - Auto Sync")

topic_options = sorted(list(VOCABULARY_DATA.keys()))
topic_labels = [VOCABULARY_DATA[k]['name'] for k in topic_options]

col_select, col_stat = st.columns([2, 1])
with col_select:
    try: idx = topic_options.index(st.session_state.selected_topic)
    except: idx = 0
    selected_label = st.selectbox("Ch·ªçn c·∫•p ƒë·ªô h·ªçc:", options=topic_labels, index=idx)

new_topic = topic_options[topic_labels.index(selected_label)]
if new_topic != st.session_state.previous_topic:
    st.session_state.selected_topic = new_topic
    st.session_state.previous_topic = new_topic
    
    st.session_state.learning_queue = copy.deepcopy(VOCABULARY_DATA[new_topic]['words'])
    st.session_state.mastered_words = []
    st.session_state.show_meaning = False
    
    save_to_gsheet(st.session_state.learning_queue, st.session_state.mastered_words)
    st.rerun()

queue = st.session_state.learning_queue
mastered = st.session_state.mastered_words

with col_stat:
    st.metric("H√†ng ƒë·ª£i", len(queue))
    st.metric("ƒê√£ thu·ªôc", len(mastered))
st.progress(len(mastered) / (len(queue) + len(mastered)) if (len(queue) + len(mastered)) > 0 else 0)

st.divider()

if not queue:
    st.success("üéâ B·∫°n ƒë√£ ho√†n th√†nh ch·ªß ƒë·ªÅ n√†y!")
    if st.button("H·ªçc l·∫°i t·ª´ ƒë·∫ßu"):
        st.session_state.learning_queue = copy.deepcopy(VOCABULARY_DATA[st.session_state.selected_topic]['words'])
        st.session_state.mastered_words = []
        save_to_gsheet(st.session_state.learning_queue, [])
        st.rerun()
else:
    word = queue[0]
    with st.container(border=True):
        st.markdown(f"<h1 style='text-align: center; color: #0068C9'>{word['english']}</h1>", unsafe_allow_html=True)
        st.markdown(f"<p style='text-align: center; color: gray'>{word.get('pronunciation', '')}</p>", unsafe_allow_html=True)
        
        # --- KHU V·ª∞C N√öT: LOA V√Ä LINK GOOGLE ---
        c_audio, c_img, c_space = st.columns([1, 1, 2])
        
        # 1. N√∫t Loa
        if 'trigger_audio' not in st.session_state: st.session_state.trigger_audio = False
        with c_audio:
             if st.button("üîä NGHE", use_container_width=True):
                 st.session_state.trigger_audio = True
        
        # 2. N√∫t Link Google Images (M·ªöI)
        with c_img:
            # T·∫°o link t√¨m ki·∫øm Google Image
            google_img_url = f"https://www.google.com.vn/search?q={word['english']}&tbm=isch"
            # N√∫t Link ƒë·∫∑c bi·ªát
            st.link_button("üîç GOOGLE IMG", google_img_url, use_container_width=True)

        # Logic Audio (D√πng h√†m autoplay_audio cho mobile)
        if st.session_state.trigger_audio:
            audio_fp = text_to_speech(word['english'])
            if audio_fp:
                autoplay_audio(audio_fp)

        st.divider()
        
        if st.session_state.show_meaning:
            st.markdown(f"<h2 style='text-align: center; color: #FF4B4B'>{word['vietnamese']}</h2>", unsafe_allow_html=True)
            st.info(f"V√≠ d·ª•: {word.get('example', '')}")
            
            c1, c2 = st.columns(2)
            with c1:
                if st.button("üòñ H·ªåC L·∫†I", use_container_width=True):
                    handle_review(word, "forget")
                    st.rerun()
            with c2:
                if st.button("üòé ƒê√É NH·ªö", type="primary", use_container_width=True):
                    handle_review(word, "remember")
                    st.rerun()
        else:
             if st.button("HI·ªÜN NGHƒ®A", type="primary", use_container_width=True):
                 st.session_state.show_meaning = True
                 st.rerun()
